{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f08a9f43-4aa8-420f-a041-e94b19897a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef6d7b42-de0a-49c1-9a47-3ea4055f6934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.model import unet_model\n",
    "from src.dataset import SegmentationDataset\n",
    "from src.data_pipeline import SegmentationDataPipeline\n",
    "from src.data_utils import plot_sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fd6761e5-7ef7-4b3b-ab55-f2b93f9ff098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Soft dice loss calculation for arbitrary batch size, number of classes, and number of spatial dimensions.\n",
    "    Assumes the `channels_last` format.\n",
    "\n",
    "    Args:\n",
    "        y_true: b x X x Y x c One hot encoding of ground truth\n",
    "        y_pred: b x X x Y x c Network output, must sum to 1 over c channel (such as after softmax)\n",
    "        epsilon: Used for numerical stability to avoid divide by zero errors\n",
    "    \"\"\"\n",
    "    axes = tuple(range(1, 3))\n",
    "    numerator = 2.0 * tf.reduce_sum((y_pred * y_true), axis=axes)\n",
    "    denominator = tf.reduce_sum(y_pred + y_true, axis=axes)\n",
    "\n",
    "    return tf.reduce_mean((numerator + epsilon) / (denominator + epsilon))\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred, epsilon=1e-6):\n",
    "    return 1 - dice_coeff(y_true, y_pred, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50ca647-9cf3-46a1-8d27-d66b90ec0cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (256, 1600)\n",
    "BATCH_SIZE = 8\n",
    "ANNOTATIONS_PATH = \"../data/train.csv\"\n",
    "TRAIN_IMG_PATH = \"../data/train_images/\"\n",
    "\n",
    "# instantiate dataset and pipelne\n",
    "sd = SegmentationDataset(\n",
    "    label_file=ANNOTATIONS_PATH,\n",
    "    img_dir_path=TRAIN_IMG_PATH,\n",
    "    img_shape=IMG_SHAPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "70d08ea4-c904-4366-94b8-098cc859572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batching\n",
      "Batching\n"
     ]
    }
   ],
   "source": [
    "# create train/test & x/y splits\n",
    "train_imgs, test_imgs = sd.get_train_test_split(test_size=0.2)\n",
    "\n",
    "X_train = sd.get_image_sequence(train_imgs)\n",
    "y_train = sd.get_label_sequence(train_imgs, label_type=\"preprocessed\")\n",
    "X_test = sd.get_image_sequence(test_imgs)\n",
    "y_test = sd.get_label_sequence(test_imgs, label_type=\"preprocessed\")\n",
    "\n",
    "sdp = SegmentationDataPipeline(\n",
    "    img_shape=IMG_SHAPE,\n",
    "    label_type=\"preprocessed\",\n",
    "    pipeline_options={\n",
    "        \"map_parallel\": None,  # off if None\n",
    "        \"cache\": False,\n",
    "        \"shuffle_buffer_size\": False,  # off if False\n",
    "        \"batch_size\": 8,\n",
    "        \"prefetch\": False,  # off if False\n",
    "    },\n",
    ")\n",
    "\n",
    "# create dataset pipelines\n",
    "train_dataset_pp = sdp(X_train, y_train)\n",
    "test_dataset_pp = sdp(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ba4487ce-9c63-487e-9d66-752a63894a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pp = list(train_dataset_pp.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c1501502-d872-47db-b4b5-547036f2d7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 256, 1600, 3), (8, 256, 1600, 5))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_pp[0][0].shape, sample_pp[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ec0e5-06d5-492d-a7a5-4668c5375244",
   "metadata": {},
   "source": [
    "### Load up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b624c4-98cf-49ff-99a1-f8ab6b5eeff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../logs/20221010-164546/best_model.h5\"\n",
    "\n",
    "unet_model = tf.keras.models.load_model(\n",
    "    MODEL_PATH,\n",
    "    custom_objects={\"dice_loss\": dice_loss, \"dice_coeff\": dice_coeff},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ee691-ee7b-4539-8182-4df29b6d50ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f70692a-a3f2-42f3-9637-dc847807e1df",
   "metadata": {},
   "source": [
    "### Debug loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5b402-aea3-4e5b-9d91-7d961002d03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd4091e-ce84-4e7e-a681-5faac0086cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d2cc7c-2b83-4fde-a16f-cdd1987e704f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb51f9-6ef2-4f61-8e22-b337ea1e3af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e491c22-2220-406f-af55-d6b6f52e3231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7001ecb1-e4bd-42cb-9394-4c33bc5d238e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00db6942-1cad-4c6c-b33c-60cf51cf04f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8360c4b4-347f-4086-8b9f-3e37aa38b730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25847a69-7e74-413e-8489-3ff59b1654a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f18c45-d853-4b5e-b8e7-c7e70b937c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b4c73-992c-4184-a70f-eab4c3bc7aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9e4cf-971f-43cc-9c7f-8a21b97115fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324383e-d816-4069-a109-7c8f36eb063c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72a386e-9aa1-42b8-b802-7e13e3afb669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd3d96c-7f6b-4026-b604-7828ffd9ebfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c855f442-3dc8-411f-a95f-96746b367348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a64de-b3c9-41b0-bd19-2c0afd02c3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78576573-8d60-4d92-9b67-6e5d0e96f97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd07f02-b077-4e9e-8497-3750d5ba7393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f5c8a0-dfe1-464b-898e-5f42d63075a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d5a284-feb5-4a8c-87ae-59c1e69419d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582eed3-ea36-4323-8249-9d7a4da245d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38630df-82cd-462d-bbd7-9084c2fa6858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa88638-928d-4201-91bb-8e8bc202f2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b485d7e-b6ad-45fc-80e5-c69a43acbd09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc64ef-edce-4722-9304-52f10cbb7064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1172ef3-8e7c-4eeb-899f-99272bdea63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b5e91-0e77-45a1-8c24-528da7a75ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088e717d-3649-4ad0-9dfb-a682a448d77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee4c5477-c7b6-4298-9a52-a13b610b8bd6",
   "metadata": {},
   "source": [
    "### Build inline channel expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31d393bb-aefa-401c-a015-fd23efbd4198",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_seq = X_train[:3]\n",
    "img_seq = [path.split(\"/\")[-1] for path in img_seq]\n",
    "label_seq = sd.get_label_sequence(img_seq, label_type=\"preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17986b97-142b-424c-9116-79336b770d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/mask_labels/8bdf6cee5.png',\n",
       " '../data/mask_labels/43438f903.png',\n",
       " '../data/mask_labels/f4c5a6321.png']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ea12b438-dda0-485c-8ad4-73d17d79f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ds = (\n",
    "    tf.data.Dataset.from_tensor_slices(label_seq)\n",
    "    .map(sdp.load_image)\n",
    "    .map(tf_add_background_channel)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a30d0001-724d-4370-a8ce-18fd6c59e9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = list(label_ds.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8343eca5-5fef-4dc1-aaf2-c49c10d2533b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1600, 5)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "26daa7eb-e8d5-495d-9df5-94be982fbd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_background_channel(mask, max_value=255.0):\n",
    "    \"\"\"\n",
    "    Prepends an additional channel to a mask label.\n",
    "\n",
    "    The additional channel assumes a value of `max_value` for each\n",
    "    pixel location that doesn't have a `max_value` in any of the existing\n",
    "    channels.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    missing_pixels = np.sum(mask, axis=-1)\n",
    "\n",
    "    where_0 = np.where(missing_pixels == 0.0)\n",
    "    where_1 = np.where(missing_pixels == max_value)\n",
    "\n",
    "    missing_pixels[where_0] = max_value\n",
    "    missing_pixels[where_1] = 0.0\n",
    "\n",
    "    missing_pixels = np.expand_dims(missing_pixels, axis=-1)\n",
    "    mask = np.concatenate((missing_pixels, mask), axis=-1)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def tf_add_background_channel(mask):\n",
    "\n",
    "    mask = tf.py_function(\n",
    "        func=add_background_channel,\n",
    "        inp=[mask],\n",
    "        Tout=[tf.float32],\n",
    "    )\n",
    "\n",
    "    return mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f082b6-b03c-4100-aac8-86fd01fa1257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3705ed-8f70-4d14-83e2-67be8c42f217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a2e79-1833-4d5c-9cc4-2c3657dd9339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c77edfa-7b78-4445-8ab9-a367c65a0dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dcd38248-a260-4b15-baf7-10d2ba328465",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = add_background_channel(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0f656973-f1d0-41c6-9b5f-ef68d68deb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pixels = np.sum(sample[0], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fe470399-e8af-43cf-b109-a29acba2ea75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(406419,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(missing_pixels == 0.0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bf0b4091-fd33-4e86-84d0-c5edbca2b567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1600)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8cab7296-fd04-499a-816a-57931e0604b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6231bca9-c6aa-4302-a6c4-3efcf3340c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "831c68c1-8307-49f0-a5a4-0e314877fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_background_channel(mask, max_value=255.0):\n",
    "    \"\"\"\n",
    "    Prepends an additional channel to a mask label.\n",
    "\n",
    "    The additional channel assumes a value of `max_value` for each\n",
    "    pixel location that doesn't have a `max_value` in any of the existing\n",
    "    channels.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    missing_pixels = tf.reduce_sum(mask, axis=-1)\n",
    "\n",
    "    where_0 = tf.cast(tf.where(missing_pixels == 0.0), tf.int64)\n",
    "    where_1 = tf.cast(tf.where(missing_pixels == max_value), tf.int64)\n",
    "\n",
    "    #     missing_pixels[where_0] = max_value\n",
    "    #     missing_pixels[where_1] = 0.0\n",
    "\n",
    "    #     missing_pixels = tf.expand_dims(missing_pixels, axis=-1)\n",
    "    #     mask = tf.concatenate((missing_pixels, mask), axis=-1)\n",
    "\n",
    "    #     return mask\n",
    "    return where_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "71f8a0a5-1d3c-4dd6-a727-53812c3911a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(406419, 2), dtype=int64, numpy=\n",
       "array([[   0,    0],\n",
       "       [   0,    1],\n",
       "       [   0,    2],\n",
       "       ...,\n",
       "       [ 255, 1597],\n",
       "       [ 255, 1598],\n",
       "       [ 255, 1599]])>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_background_channel(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f5182364-fc14-4977-bf68-3ead1a6ca4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pixels = tf.reduce_sum(sample[0], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3f79ea92-036a-45da-8b46-b3c1f51cfd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 1600), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f46d9503-55d8-42c8-810e-a361780258d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "where = tf.where(missing_pixels == 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "aa3159cd-5306-448a-937c-70092c1e404b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3181, 2), dtype=int64, numpy=\n",
       "array([[ 151, 1288],\n",
       "       [ 151, 1289],\n",
       "       [ 151, 1290],\n",
       "       ...,\n",
       "       [ 221, 1318],\n",
       "       [ 222, 1317],\n",
       "       [ 222, 1318]])>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8d8ee8-d4a4-4363-b16d-aac9733c7352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940db954-7d02-4d60-82f4-8a6645d87146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35563ffb-a1a7-4f25-93f8-1f59cbdaedb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2fb34-c374-4a12-a858-8021f5c2545e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e72183-ae86-4ed7-bbd3-83159088b536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab47497-a327-449a-b046-6bb7c374a4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cc651eaa-0a5d-4052-8fdf-ba7e187152e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3181,), dtype=int64, numpy=array([151, 151, 151, ..., 221, 222, 222])>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where[..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e40fe99f-3015-4208-b4e0-bae33fc40812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3181,), dtype=int64, numpy=array([1288, 1289, 1290, ..., 1318, 1317, 1318])>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where[..., 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f197900e-9bfc-4f59-a4e7-d8a8be2678f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4856c3c1-7a10-411d-a3f1-5345d3f7efc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63225d08-0a74-40f2-b4a0-624124b6cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f21179-8e73-447e-bb30-b776d6321d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb32027-1539-43bd-867c-a4406472b4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a582ff9f-b9c6-4726-b929-40dcb45f0add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6936876-161d-4843-8342-54f6fbcf2369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8ed89-58ef-4059-8413-cae378e29efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c0fb0bd-7346-4940-8938-a4d7d7aa0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_pixels = tf.reduce_sum(sample[0], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b7bad0c-c7f8-4a5c-90b3-af326396f908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 1600), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.conmissing_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5422d668-0172-46ae-9063-3b169b64c7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 1600), dtype=int16, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int16)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(missing_pixels, tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c34c2-9f17-4737-a5f3-81408bd9998e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4786bf-2f06-49d9-9c81-9e9b92d04359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "614deb56-a7bb-49f5-b7a4-8b4e2d4774d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 1600), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(sample[0], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4717e72-0645-4203-8e4a-73415b0a276e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76fd82e-f674-48d7-88ac-44cc77c746de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42800e23-3e30-47b8-8011-64644893f37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a14dd7-f5d1-4c50-b3c0-e9d273a79788",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.where("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b4f8f-5d4c-4193-9d9e-ee299cd4505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.expand_dims("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47c8d2-e341-4b27-8fd9-bb45a1a296da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32610961-ea1f-4b36-b247-ab3b6ae1e1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1600, 4)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33183100-6ec7-4435-8727-a8d6677171e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1600)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sample[0], axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f46691-efd2-443e-bdfb-6d52f9f63507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bef883-04e0-458e-a307-d11227c2f81b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ab159-5f15-4bac-ad56-f4a65473ef7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8ca7e-c4e7-4488-aa22-d3e13d1381d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fef8d7-2ca3-4f0e-8fe0-54afcbcc6257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313ed33-de88-4bdf-bc55-9c3f2a567bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd1a38c8-1d09-4443-a9f0-bb24c7aaa094",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = sd.prepare_mask_label(label_seq[0], one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a924ea0d-30ee-4132-bce6-bce42dc5c659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 1600, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df082ef-550a-497b-8ca9-202519c62cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#         # create \"background\" channel and add to mask\n",
    "#         missing_pixels = np.sum(mask, axis=-1)\n",
    "\n",
    "#         where_0 = np.where(missing_pixels == 0.0)\n",
    "#         where_1 = np.where(missing_pixels == 1.0)\n",
    "\n",
    "#         missing_pixels[where_0] = 1.0\n",
    "#         missing_pixels[where_1] = 0.0\n",
    "\n",
    "#         missing_pixels = np.expand_dims(missing_pixels, axis=-1)\n",
    "#         mask = np.concatenate((missing_pixels, mask), axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
