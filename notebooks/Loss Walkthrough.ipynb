{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation - Metrics & Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 13:49:50.577595: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-18 13:49:54.254545: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/cuda/lib::/usr/lib/hadoop/lib/native\n",
      "2022-10-18 13:49:54.254756: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/cuda/lib::/usr/lib/hadoop/lib/native\n",
      "2022-10-18 13:49:54.254776: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Data\n",
    "\n",
    "Let's build dummy examples of a `y_true` ground truth mask and a `y_pred` prediction mask to help understand the inner workings of the various loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth mask\n",
    "# set first channel as background, 2 pixel defect\n",
    "y_true = np.zeros((2, 4, 4, 3))\n",
    "y_true[0, :, :, 0] = 1.0\n",
    "y_true[0, (1,2), 1, 0] = 0.0\n",
    "y_true[0, (1,2), 1, 1] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 1., 1., 1.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[0, :, :, 0], y_true[0, :, :, 1], y_true[0, :, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_mask\n",
    "# set first channel as background, 2 pixel defect\n",
    "y_pred = np.zeros((2, 4, 4, 3))\n",
    "y_pred[0, :, :, 0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0, :, :, 0], y_pred[0, :, :, 1], y_pred[0, :, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Index | Intersection over Union (IoU)\n",
    "\n",
    "The Jaccard Index (aka Intersection-Over-Union) is a common evaluation metric for semantic segmentation.\n",
    "\n",
    "<center><img src=\"../images/IoU.png\"/></center>\n",
    "\n",
    "\n",
    "$$\n",
    "...\n",
    "$$\n",
    "\n",
    "$$ IoU = \\frac{X \\cap Y }{X \\cup Y } = \\frac{TP}{TP + FP + FN} $$\n",
    "\n",
    "$$\n",
    "...\n",
    "$$\n",
    "\n",
    "When applied to boolean data, we can represent IoU with true postitives (TP), false positives (FP), and false negatives (FN), as seen above.\n",
    "\n",
    "[Image Credit](https://en.wikipedia.org/wiki/Jaccard_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred, smooth=1e-6):\n",
    "\n",
    "    y_true_pos = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_pos = tf.keras.layers.Flatten()(y_pred)\n",
    "\n",
    "    true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = tf.reduce_sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = tf.reduce_sum((1 - y_true_pos) * y_pred_pos)\n",
    "\n",
    "\n",
    "    return (true_pos + smooth) / (\n",
    "        true_pos + false_pos + false_neg + smooth\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 18:59:48.989573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu::/usr/lib/hadoop/lib/native\n",
      "2022-10-13 18:59:48.989760: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-13 18:59:48.989877: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (uyj6gicxuni7nri3): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.77777773"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice Similarity Coefficient & Loss\n",
    "\n",
    "The dice similarity coefficient (DSC) is a commonly used measure of overlap between a predicted and ground truth mask. The dice coefficient excludes the background class from the loss calculation so that error signal is attributed to defect mask predictions only. This ensures the pixel-wise class imbalance of the background class does not dominate loss contributions in comparison to the underrepresented defect pixels.\n",
    "\n",
    "The dice coefficient ranges from 0-1, where 1 represents absolute overlap, while 0 indicates no overlap at all. Therefore, we can use 1 - DSC as a representative loss function that we aim to minimize.\n",
    "\n",
    "<center><img src=\"../images/dice_coeff.png\"/></center>\n",
    "\n",
    "$$\n",
    "...\n",
    "$$\n",
    "\n",
    "$$ DSC = \\frac{2 | X \\cap Y | }{|X| + |Y|} = \\frac{2TP}{2TP + FP + FN} $$\n",
    "\n",
    "$$\n",
    "...\n",
    "$$\n",
    "\n",
    "Here, $|X|$ and $|Y|$ represent the number of elements in each set. Therefore, DSC is twice the number of pixels in common between two masks divided by the sum of number of pixels in each mask. When applied to boolean data, we can represent DSC with true postitives (TP), false positives (FP), and false negatives (FN), as seen above.\n",
    "\n",
    "[Image Credit](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.kaggle.com%2Fcode%2Fyerramvarun%2Funderstanding-dice-coefficient&psig=AOvVaw2kmPKQbhzdAWBKpJ0xzmtw&ust=1665757231787000&source=images&cd=vfe&ved=0CAsQjRxqFwoTCICjp7Oz3foCFQAAAAAdAAAAABAM_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred, smooth=1e-6, remove_bkg=False):\n",
    "\n",
    "    if remove_bkg:\n",
    "        # remove background channel from loss calculation\n",
    "        y_true = y_true[:, :, :, 1:]\n",
    "        y_pred = y_pred[:, :, :, 1:]\n",
    "\n",
    "    y_true_pos = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_pos = tf.keras.layers.Flatten()(y_pred)\n",
    "\n",
    "    true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = tf.reduce_sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = tf.reduce_sum((1 - y_true_pos) * y_pred_pos)\n",
    "\n",
    "\n",
    "    return (2.0 * true_pos + smooth) / (\n",
    "        2.0 *true_pos + false_pos + false_neg + smooth\n",
    "    )\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6, remove_bkg=False):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred, smooth, remove_bkg)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12499994, 0.9999995)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_loss(y_true, y_pred, remove_bkg=False).numpy(), dice_loss(y_true, y_pred, remove_bkg=True).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that when the background class is included in the loss calculation, loss is relatively low (0.12) despite the fact that the prediction mask didn't correctly predict a single defect pixel. By removing the background class from the calculation, the loss signal focuses solely on defective classes. As we see, this results in a high loss (0.99) as we would expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tversky Index\n",
    "\n",
    "As seen above, Dice Loss is a harmonic mean of precision and recall that weights false positives and false negatives equally. The Tversky Index is a generalization of Dice Similarity Coefficient that affords a tunable parameter to weight FP's and FN's differently. This tradeoff between precision and recall allows us to place more emphasis on false negative, which are commonly the issue when dealing with highly imbalanced data. \n",
    "\n",
    "$$\n",
    "...\n",
    "$$\n",
    "\n",
    "$$ TI = \\frac{TP}{TP + \\alpha FP + (1-\\alpha)FN} $$\n",
    "\n",
    "$$\n",
    "...\n",
    "$$\n",
    "\n",
    "Here, Tversky Index introduces the $\\alpha$ parameter. In the case where $\\alpha=0.5$, TI simplifies to the dice coefficient. However by setting  $\\alpha>0.5$ we can enforce a higher penalty on false negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tversky(y_true, y_pred, alpha = 0.7, smooth=1e-6):\n",
    "    # Focal Tversky loss, brought to you by:  https://github.com/nabsabraham/focal-tversky-unet\n",
    "\n",
    "    # remove background channel from loss calculation\n",
    "    y_true = y_true[:, :, :, 1:]\n",
    "    y_pred = y_pred[:, :, :, 1:]\n",
    "\n",
    "    y_true_pos = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_pos = tf.keras.layers.Flatten()(y_pred)\n",
    "    true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = tf.reduce_sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = tf.reduce_sum((1 - y_true_pos) * y_pred_pos)\n",
    "\n",
    "\n",
    "    return (true_pos + smooth) / (\n",
    "        true_pos + (alpha * false_neg) + ((1 - alpha) * false_pos) + smooth\n",
    "    )\n",
    "\n",
    "def tversky_loss(y_true, y_pred, alpha = 0.7, smooth=1e-6):\n",
    "    return 1 - tversky(y_true, y_pred, alpha, smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 13:50:10.833441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 13:50:10.980368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 13:50:10.981729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 13:50:10.987570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 13:50:10.988799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 13:50:10.989460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 13:50:12.840190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 13:50:12.840729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 13:50:12.841219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 13:50:12.841691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 367 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.999995, 0.99999946)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tversky_loss(y_true, y_pred, alpha=0.1).numpy(), tversky_loss(y_true, y_pred, alpha=0.9).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Sample Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 4, 4, 3), (2, 4, 4, 3))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff_old(y_true, y_pred, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Soft dice loss calculation for arbitrary batch size, number of classes, and number of spatial dimensions.\n",
    "    Assumes the `channels_last` format.\n",
    "\n",
    "    Args:\n",
    "        y_true: b x X x Y x c One hot encoding of ground truth\n",
    "        y_pred: b x X x Y x c Network output, must sum to 1 over c channel (such as after softmax)\n",
    "        epsilon: Used for numerical stability to avoid divide by zero errors\n",
    "    \"\"\"\n",
    "    axes = tuple(range(1, 3))\n",
    "    numerator = 2.0 * tf.reduce_sum((y_pred * y_true), axis=axes)\n",
    "    denominator = tf.reduce_sum(y_pred + y_true, axis=axes)\n",
    "\n",
    "    return tf.reduce_mean((numerator + epsilon) / (denominator + epsilon))\n",
    "    # return numerator, denominator\n",
    "\n",
    "def dice_coeff(y_true, y_pred, smooth=1e-6, remove_bkg=False):\n",
    "\n",
    "    if remove_bkg:\n",
    "        # remove background channel from loss calculation\n",
    "        y_true = y_true[:, :, :, 1:]\n",
    "        y_pred = y_pred[:, :, :, 1:]\n",
    "\n",
    "    y_true_pos = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_pos = tf.keras.layers.Flatten()(y_pred)\n",
    "\n",
    "    true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = tf.reduce_sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = tf.reduce_sum((1 - y_true_pos) * y_pred_pos)\n",
    "\n",
    "    numerator = (2.0 * true_pos + smooth)\n",
    "    denominator = (\n",
    "        2.0 *true_pos + false_pos + false_neg + smooth\n",
    "    )\n",
    "\n",
    "    return (2.0 * true_pos + smooth) / (\n",
    "        2.0 *true_pos + false_pos + false_neg + smooth\n",
    "    )\n",
    "    # return numerator, denominator\n",
    "\n",
    "def dice_coeff_jj(y_true, y_pred, epsilon=1e-6): \n",
    "    ''' \n",
    "    Soft dice loss calculation for arbitrary batch size, number of classes, and number of spatial dimensions.\n",
    "    Assumes the `channels_last` format.\n",
    "  \n",
    "    # Arguments\n",
    "        y_true: b x X x Y( x Z...) x c One hot encoding of ground truth\n",
    "        y_pred: b x X x Y( x Z...) x c Network output, must sum to 1 over c channel (such as after softmax) \n",
    "        epsilon: Used for numerical stability to avoid divide by zero errors\n",
    "    \n",
    "    # References\n",
    "        V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation \n",
    "        https://arxiv.org/abs/1606.04797\n",
    "        More details on Dice loss formulation \n",
    "        https://mediatum.ub.tum.de/doc/1395260/1395260.pdf (page 72)\n",
    "        \n",
    "        Adapted from https://github.com/Lasagne/Recipes/issues/99#issuecomment-347775022\n",
    "    '''\n",
    "    \n",
    "    # skip the batch and class axis for calculating Dice score\n",
    "    axes = tuple(range(1, len(y_pred.shape)-1)) \n",
    "    numerator = 2. * np.sum(y_pred * y_true, axes)\n",
    "    denominator = np.sum(np.square(y_pred) + np.square(y_true), axes)\n",
    "    \n",
    "    return np.mean((numerator + epsilon) / (denominator + epsilon)) # average over classes and batch\n",
    "    # return numerator, denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.8222223059258843>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_coeff_old(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.87500006>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_coeff(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[28.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]]),\n",
       " array([[30.,  2.,  0.],\n",
       "        [ 0.,  0.,  0.]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerator, denominator = dice_coeff_jj(y_true, y_pred)\n",
    "epsilon = 1e-6\n",
    "numerator, denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.33333336e-01, 4.99999750e-07, 1.00000000e+00],\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(numerator + epsilon) / (denominator + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8222223059258843"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((numerator + epsilon) / (denominator + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.8222223059258843>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean((numerator + epsilon) / (denominator + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([0.35555539, 0.        ])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- tf.reduce_mean((numerator + epsilon) / (denominator + epsilon), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28/30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Tversky loss function for image segmentation using 3D fully convolutional deep networks](https://arxiv.org/abs/1706.05721)\n",
    "- [A Novel Focal Tversky Loss Function with Improved Attention U-Net for Lesion Segmentation](https://arxiv.org/pdf/1810.07842.pdf)\n",
    "- [Dealing with class imbalanced image datasets using Focal Tversky Loss](https://towardsdatascience.com/dealing-with-class-imbalanced-image-datasets-1cbd17de76b5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per class evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 1., 1., 1.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[0, :, :, 0], y_true[0, :, :, 1], y_true[0, :, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0, :, :, 0], y_pred[0, :, :, 1], y_pred[0, :, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff_per_class(y_true, y_pred, smooth=1e-6, remove_bkg=False):\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    for class_idx in range(y_true.shape[-1]):\n",
    "\n",
    "        y_true_class = y_true[..., class_idx]\n",
    "        y_pred_class = y_pred[..., class_idx]\n",
    "\n",
    "        y_true_pos = tf.keras.layers.Flatten()(y_true_class)\n",
    "        y_pred_pos = tf.keras.layers.Flatten()(y_pred_class)\n",
    "\n",
    "        true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
    "        false_neg = tf.reduce_sum(y_true_pos * (1 - y_pred_pos))\n",
    "        false_pos = tf.reduce_sum((1 - y_true_pos) * y_pred_pos)\n",
    "\n",
    "        score = (2.0 * true_pos + smooth) / (\n",
    "        2.0 *true_pos + false_pos + false_neg + smooth\n",
    "    )\n",
    "\n",
    "        metrics[class_idx] = score.numpy()\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.93333334, 1: 4.9999977e-07, 2: 1.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_coeff_per_class(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
