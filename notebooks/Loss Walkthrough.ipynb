{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation - Metrics & Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 18:59:35.942726: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu::/usr/lib/hadoop/lib/native\n",
      "2022-10-13 18:59:35.942870: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-13 18:59:36.072590: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-13 18:59:40.138531: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu::/usr/lib/hadoop/lib/native\n",
      "2022-10-13 18:59:40.140344: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu::/usr/lib/hadoop/lib/native\n",
      "2022-10-13 18:59:40.140387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Data\n",
    "\n",
    "Let's build dummy examples of a `y_true` ground truth mask and a `y_pred` prediction mask to help understand the inner workings of the various loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth mask\n",
    "# set first channel as background, 2 pixel defect\n",
    "y_true = np.zeros((1, 4, 4, 3))\n",
    "y_true[0, :, :, 0] = 1.0\n",
    "y_true[0, (1,2), 1, 0] = 0.0\n",
    "y_true[0, (1,2), 1, 1] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 1., 1., 1.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[0, :, :, 0], y_true[0, :, :, 1], y_true[0, :, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_mask\n",
    "# set first channel as background, 2 pixel defect\n",
    "y_pred = np.zeros((1, 4, 4, 3))\n",
    "y_pred[0, :, :, 0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0, :, :, 0], y_pred[0, :, :, 1], y_pred[0, :, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Index | Intersection over Union (IoU)\n",
    "\n",
    "The Jaccard Index (aka Intersection-Over-Union) is a common evaluation metric for semantic segmentation.\n",
    "\n",
    "<center><img src=\"../images/IoU.png\"/></center>\n",
    "\n",
    "\n",
    "$$\n",
    "...\n",
    "$$\n",
    "\n",
    "$$ IoU = \\frac{X \\cap Y }{X \\cup Y } = \\frac{TP}{TP + FP + FN} $$\n",
    "\n",
    "$$\n",
    "...\n",
    "$$\n",
    "\n",
    "When applied to boolean data, we can represent IoU with true postitives (TP), false positives (FP), and false negatives (FN), as seen above.\n",
    "\n",
    "[Image Credit](https://en.wikipedia.org/wiki/Jaccard_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred, smooth=1e-6):\n",
    "\n",
    "    y_true_pos = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_pos = tf.keras.layers.Flatten()(y_pred)\n",
    "\n",
    "    true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = tf.reduce_sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = tf.reduce_sum((1 - y_true_pos) * y_pred_pos)\n",
    "\n",
    "\n",
    "    return (true_pos + smooth) / (\n",
    "        true_pos + false_pos + false_neg + smooth\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 18:59:48.989573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/x86_64-linux-gnu::/usr/lib/hadoop/lib/native\n",
      "2022-10-13 18:59:48.989760: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-13 18:59:48.989877: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (uyj6gicxuni7nri3): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.77777773"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice Similarity Coefficient & Loss\n",
    "\n",
    "The dice similarity coefficient (DSC) is a commonly used measure of overlap between a predicted and ground truth mask. The dice coefficient excludes the background class from the loss calculation so that error signal is attributed to defect mask predictions only. This ensures the pixel-wise class imbalance of the background class does not dominate loss contributions in comparison to the underrepresented defect pixels.\n",
    "\n",
    "The dice coefficient ranges from 0-1, where 1 represents absolute overlap, while 0 indicates no overlap at all. Therefore, we can use 1 - DSC as a representative loss function that we aim to minimize.\n",
    "\n",
    "<center><img src=\"../images/dice_coeff.png\"/></center>\n",
    "\n",
    "$$\n",
    "...\n",
    "$$\n",
    "\n",
    "$$ DSC = \\frac{2 | X \\cap Y | }{|X| + |Y|} = \\frac{2TP}{2TP + FP + FN} $$\n",
    "\n",
    "$$\n",
    "...\n",
    "$$\n",
    "\n",
    "Here, $|X|$ and $|Y|$ represent the number of elements in each set. Therefore, DSC is twice the number of pixels in common between two masks divided by the sum of number of pixels in each mask. When applied to boolean data, we can represent DSC with true postitives (TP), false positives (FP), and false negatives (FN), as seen above.\n",
    "\n",
    "[Image Credit](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.kaggle.com%2Fcode%2Fyerramvarun%2Funderstanding-dice-coefficient&psig=AOvVaw2kmPKQbhzdAWBKpJ0xzmtw&ust=1665757231787000&source=images&cd=vfe&ved=0CAsQjRxqFwoTCICjp7Oz3foCFQAAAAAdAAAAABAM_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred, smooth=1e-6, remove_bkg=False):\n",
    "\n",
    "    if remove_bkg:\n",
    "        # remove background channel from loss calculation\n",
    "        y_true = y_true[:, :, :, 1:]\n",
    "        y_pred = y_pred[:, :, :, 1:]\n",
    "\n",
    "    y_true_pos = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_pos = tf.keras.layers.Flatten()(y_pred)\n",
    "\n",
    "    true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = tf.reduce_sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = tf.reduce_sum((1 - y_true_pos) * y_pred_pos)\n",
    "\n",
    "\n",
    "    return (2.0 * true_pos + smooth) / (\n",
    "        2.0 *true_pos + false_pos + false_neg + smooth\n",
    "    )\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1e-6, remove_bkg=False):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred, smooth, remove_bkg)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12499994, 0.9999995)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_loss(y_true, y_pred, remove_bkg=False).numpy(), dice_loss(y_true, y_pred, remove_bkg=True).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that when the background class is included in the loss calculation, loss is relatively low (0.12) despite the fact that the prediction mask didn't correctly predict a single defect pixel. By removing the background class from the calculation, the loss signal focuses solely on defective classes. As we see, this results in a high loss (0.99) as we would expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tversky Index\n",
    "\n",
    "As seen above, Dice Loss is a harmonic mean of precision and recall that weights false positives and false negatives equally. The Tversky Index is a generalization of Dice Similarity Coefficient that affords a tunable parameter to weight FP's and FN's differently. This tradeoff between precision and recall allows us to place more emphasis on false negative, which are commonly the issue when dealing with highly imbalanced data. \n",
    "\n",
    "$$\n",
    "...\n",
    "$$\n",
    "\n",
    "$$ TI = \\frac{TP}{TP + \\alpha FP + (1-\\alpha)FN} $$\n",
    "\n",
    "$$\n",
    "...\n",
    "$$\n",
    "\n",
    "Here, Tversky Index introduces the $\\alpha$ parameter. In the case where $\\alpha=0.5$, TI simplifies to the dice coefficient. However by setting  $\\alpha>0.5$ we can enforce a higher penalty on false negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tversky(y_true, y_pred, alpha = 0.7, smooth=1e-6):\n",
    "    # Focal Tversky loss, brought to you by:  https://github.com/nabsabraham/focal-tversky-unet\n",
    "\n",
    "    # remove background channel from loss calculation\n",
    "    y_true = y_true[:, :, :, 1:]\n",
    "    y_pred = y_pred[:, :, :, 1:]\n",
    "\n",
    "    y_true_pos = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_pos = tf.keras.layers.Flatten()(y_pred)\n",
    "    true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = tf.reduce_sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = tf.reduce_sum((1 - y_true_pos) * y_pred_pos)\n",
    "\n",
    "\n",
    "    return (true_pos + smooth) / (\n",
    "        true_pos + (alpha * false_neg) + ((1 - alpha) * false_pos) + smooth\n",
    "    )\n",
    "\n",
    "def tversky_loss(y_true, y_pred, alpha = 0.7, smooth=1e-6):\n",
    "    return 1 - tversky(y_true, y_pred, alpha, smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.999995, 0.99999946)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tversky_loss(y_true, y_pred, alpha=0.1).numpy(), tversky_loss(y_true, y_pred, alpha=0.9).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Tversky loss function for image segmentation using 3D fully convolutional deep networks](https://arxiv.org/abs/1706.05721)\n",
    "- [A Novel Focal Tversky Loss Function with Improved Attention U-Net for Lesion Segmentation](https://arxiv.org/pdf/1810.07842.pdf)\n",
    "- [Dealing with class imbalanced image datasets using Focal Tversky Loss](https://towardsdatascience.com/dealing-with-class-imbalanced-image-datasets-1cbd17de76b5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per class evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 1., 1., 1.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[0, :, :, 0], y_true[0, :, :, 1], y_true[0, :, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]),\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0, :, :, 0], y_pred[0, :, :, 1], y_pred[0, :, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff_per_class(y_true, y_pred, smooth=1e-6, remove_bkg=False):\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    for class_idx in range(y_true.shape[-1]):\n",
    "\n",
    "        y_true_class = y_true[..., class_idx]\n",
    "        y_pred_class = y_pred[..., class_idx]\n",
    "\n",
    "        y_true_pos = tf.keras.layers.Flatten()(y_true_class)\n",
    "        y_pred_pos = tf.keras.layers.Flatten()(y_pred_class)\n",
    "\n",
    "        true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
    "        false_neg = tf.reduce_sum(y_true_pos * (1 - y_pred_pos))\n",
    "        false_pos = tf.reduce_sum((1 - y_true_pos) * y_pred_pos)\n",
    "\n",
    "        score = (2.0 * true_pos + smooth) / (\n",
    "        2.0 *true_pos + false_pos + false_neg + smooth\n",
    "    )\n",
    "\n",
    "        metrics[class_idx] = score.numpy()\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.93333334, 1: 4.9999977e-07, 2: 1.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_coeff_per_class(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
